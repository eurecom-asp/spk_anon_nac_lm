diff --git a/anonymizer.py b/anonymizer.py
index be34be47..e7321092 100644
--- a/anonymizer.py
+++ b/anonymizer.py
@@ -11,9 +11,10 @@ from TTS.tts.layers.bark.hubert.hubert_manager import HubertManager
 from TTS.tts.layers.bark.hubert.kmeans_hubert import CustomHubert
 from TTS.tts.layers.bark.hubert.tokenizer import HubertTokenizer
 
+from vocos import Vocos
 
 class Anonymizer(torch.nn.Module):
-    def __init__(self, checkpoint_dir: str, voice_dirs: Union[list[str], None] = None):
+    def __init__(self, checkpoint_dir: str, voice_dirs: Union[list[str], None] = None, use_vocos=True):
         super().__init__()
 
         # 1. initialize Bark
@@ -34,6 +35,11 @@ class Anonymizer(torch.nn.Module):
         self.voice_dirs = voice_dirs
         self.sample_rate = self.model.config.sample_rate
 
+        self.use_vocos = use_vocos
+        if self.use_vocos:
+        # 3. if setting is given, initialize culos, i mean vocos
+            self.vocos = Vocos.from_pretrained("charactr/vocos-encodec-24khz")
+
     def forward(
             self,
             audio: Union[torch.Tensor, str],
@@ -69,10 +75,24 @@ class Anonymizer(torch.nn.Module):
         # 'temp' here is only the coarse temperature. The fine temperature is internally fixed to 0.5
         # (i fiddled with it a bit and it does seem a bit of a sweet spot, any higher and the audio gets a bit dirty)
         # the other two returned values are coarse and fine tokens, we don't need them for now
-        audio_arr, _, _ = self.model.semantic_to_waveform(
-            semantic_tokens, history_prompt=history_prompt, temp=coarse_temperature
-        )
-        return audio_arr
+        if not self.use_vocos:
+            audio_arr, x_coarse_gen, x_fine_gen = self.model.semantic_to_waveform(
+                semantic_tokens, history_prompt=history_prompt, temp=coarse_temperature
+            )
+        else:
+            x_coarse_gen, x_fine_gen = self.model.semantic_to_fine(
+                semantic_tokens, history_prompt=history_prompt, coarse_temp=coarse_temperature
+            )
+            x_fine_gen = torch.tensor(x_fine_gen, device=self.model.device)
+            features = self.vocos.codes_to_features(x_fine_gen)
+            # i'm keeping the bandwidth the same as encodec (6 kbps)
+            # i genuinely have no idea what difference it makes inside vocos
+            # it seems to only internally affect layer norms, where they train the scale/bias according to the bitrate
+            # do they know that torch's layer norm already scales? I guess they do.
+            # yeah, the index '2' is 6 kbps according to their git
+            bandwidth_id = torch.tensor([2], device=self.model.device)
+            audio_arr = self.vocos.decode(features, bandwidth_id=bandwidth_id)
+        return audio_arr, x_coarse_gen, x_fine_gen
 
 
 checkpoint_dir = '/homes/panariel/.local/share/tts/tts_models--multilingual--multi-dataset--bark'
